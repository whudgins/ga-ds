{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is a python library providing rich functionality on top of numpy. In addition to 'Excel like' tables, Pandas works well with numpy constructs and scikit-learn.\n",
    "\n",
    "For more information, the docs are available at:\n",
    "http://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Series\n",
    "\n",
    "Pandas series are like 1-dimensional numpy arrays, except that they are _labeled_, or have indices. In addition, the elements can be numeric, bools, strings, date time objects, functional objects, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can create the Pandas series from a Python list similar to Numpy\n",
    "flt_series = pd.Series( [1.0,-2, .43434] )\n",
    "flt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can also pass in a Numpy ndarray\n",
    "flt_series = pd.Series( np.random.random(5) )\n",
    "flt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dtype here is int64\n",
    "int_series = pd.Series( np.random.random_integers(0,5,5) )\n",
    "int_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dtype here is object\n",
    "str_series = pd.Series([x*2 for x in 'abcd'])\n",
    "str_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tup_series = pd.Series([(x,x+1) for x in range(4)])\n",
    "tup_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_series = pd.Series( [map for x in range(5) ])\n",
    "fun_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unlike numpy, all elements of the series do not have to be the same type\n",
    "mix_series = pd.Series( [1.0, -2, map, 'aa', np.nan])\n",
    "mix_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can use generic head() or head(# elements)\n",
    "print mix_series.head()\n",
    "print mix_series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can use generic tail() or tail(# elements)\n",
    "print mix_series.tail()\n",
    "print mix_series.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for null/Nan on each element\n",
    "mix_series.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can mix in Numpy types/operations with pandas objects\n",
    "np.any( mix_series.isnull() ) #Are ANY of the elements null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create two pd series with `a = [1,2,3,4]` and `b = [2.0, 3.0, 1.0,-1.2]`. Use `head(1)` to view only the first item of `a`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Create a new pd series c = [-2, 0, 3, np.nan ]. Add `a + c`. What do you get?**\n",
    "\n",
    "Hint: you can use the `+` operator, or `np.add`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) What does comparing the 4th element of c to np.nan evaluate to? What does imply when comparing objects with multiple nan values? Test this theory using np.all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Create a pd Series where a = [1,2,3,'c',None,np.nan]. We have seen two methods so far for evaluating nans. `np.isnan` and `pd.isnull`. Evaluate both functions on `a`. What do you see?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes\n",
    "\n",
    "\n",
    "Each row of the pandas series has an index by default. In fact, you can specify your own indices \n",
    "\n",
    "Why have indices? Think of them as not only ways to conveniently label rows, but also can perform fast lookups, grouping operations, descriptive stats associated with these indices.\n",
    "\n",
    "(These are not the same as the _labels_ mentioned in supervised learning)\n",
    "\n",
    "\n",
    "Indices can be strings, integers, or even time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indSeries1 = pd.Series(np.random.random(5), \n",
    "                       index=['CA','AK','IL','IN','NY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indSeries2 = pd.Series(np.random.random(3), \n",
    "                       index=['CA','IL','WA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Really cool! Matches the indices together and adds up by index\n",
    "indSeries1 + indSeries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datSeries = pd.Series(np.random.random(5), \n",
    "                      index=pd.date_range('2015-01-01','2015-06-01',\n",
    "                                           freq='m'))\n",
    "datSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just as a 'you can do this', if the index is a pd.date_range object,\n",
    "# then you can resample by frequency\n",
    "datSeries.resample('q') #Resample by quarter\n",
    "datSeries.resample('d') #Resample by day, will NA fill\n",
    "datSeries.resample('d', fill_method='ffill') #Resample by day, will forward will"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes need not be strings. They can be integers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datSeries = pd.Series(np.random.random(10),\n",
    "                     index=np.random.randint(0,1000,10))\n",
    "datSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pandas series have multiple aggregation/description methods:\n",
    "# http://pandas.pydata.org/pandas-docs/version/0.17.1/api.html#computations-descriptive-stats\n",
    "\n",
    "\n",
    "datSeries = pd.Series([1,2,5,3,5,3,2], \n",
    "                      index=[x for x in 'abcdefg'])\n",
    "datSeries.value_counts()\n",
    "datSeries.unique()\n",
    "datSeries.nunique()\n",
    "datSeries.all()\n",
    "datSeries.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create two Pandas Series with various indices. `a` is a series with `arange(5)` having indices ['CA','IL','PA','IN','WA']. `b`  is a series with `arange(5)` having indices ['CA','MN','IL','IN','WA'].**\n",
    "\n",
    "**Add `a + b`. What happens in the result?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Repeat the sum, but instead of `a+b`, try `a.add(b, fill_value=0)`. How does the result change?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Create two series. `a` is `arange(1,5)` having index `['a','b','c',a']`. `b` is `arange(1,5)` having index `['a','a','c','d']`. What happens when you add `a + b`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Basics\n",
    "DataFrames are extensions of series into tables. They can have multiple indices (rows) and columns. Think of data frames as horizontally stacked series sharing the same set of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generates default integer indexes (rows) and columns\n",
    "df = pd.DataFrame(np.random.random((5,5)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Can pass in the index (row) labels, as well as column labels instead\n",
    "df_idx = pd.date_range('2015-01-01','2015-01-05',freq='d')\n",
    "df_col = ['sun','mon','tues','wed','thurs']\n",
    "df = pd.DataFrame(np.random.random((5,5)),index=df_idx, columns=df_col)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intIndex = np.random.randint(0,100,10)\n",
    "df2 = pd.DataFrame({'a': 1.,\n",
    "                    'b': pd.Timestamp('2015-01-01'),\n",
    "                    'c': pd.Series(np.random.random(10),index=intIndex),\n",
    "                    'd': 'foo'},\n",
    "                  index=intIndex)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Multiple columnwise aggregations available. More available too! View docs\n",
    "df.head()\n",
    "df.tail()\n",
    "df.mean()\n",
    "df.min()\n",
    "df.cumsum()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns #List the column labels of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index # List the rows labels of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Unlike numpy, there is no row x column addressing using only [ ]\n",
    "#i.e. x[2,4] would work for a numpy array. x[2,4] does NOT work for a pandas dataframe\n",
    "df[0,0] #Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sun # the columns can be addressed directly as pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['sun'] # this is also valid. This returns a pd Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ ['sun'] ] # Index by label vs. array returns different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[ ['sun','mon'] ] # Can just select certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Since addressing single column returns a Series\n",
    "# We can call the Series description fn's on them\n",
    "df[ 'sun' ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['fri'] = 1.0* df['wed'] + 2.0 * df['thurs']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful here. axis is switched with pandas. Here, axis=0 refers to rows, axis=1 refers to columns. Drop requires an `index label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('fri',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('2015-01-01',axis=0) #wont work. '2015-01-01' is not the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop( pd.Timestamp('2015-01-01'), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create a dataframe where the indexes are every day from 1/1/2015 to 12/31/2015 and the columns are `calories` and `weight`. Calories should be uniform random integers from 1400 to 2000. Weight should be random normal generated having mean 180 and variance 20.**\n",
    "\n",
    "Hint: Use np.random.randint and np.random.normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Add a new column `mood` to the dataframe having random uniform floats from 0 to 1.**\n",
    "\n",
    "Hint: Use np.random.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) It turns out having data points everyday is really noisy. Resample the data to monthly estimates. Use method of mean to resample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create dataframes using a dictionary of objects for each column. Again, the index need not be string types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting  Dataframes\n",
    "\n",
    "Subsetting dataframes works similarly to numpy, but with some additional functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_idx = pd.date_range('2015-01-01','2015-01-05',freq='d')\n",
    "df_col = ['sun','mon','tues','wed','thurs']\n",
    "df = pd.DataFrame(np.random.random((5,5)),index=df_idx, columns=df_col)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ df['sun'] > .5 ] #Subset certain rows, where the 'sun' column for that row is greater than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[ (df['sun'] > .5) & (df['mon'] < .5) ] #multiple conditions, use tuples for each condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing functions summary\n",
    "\n",
    "Pandas Dataframes support various methods for indexing:\n",
    "\n",
    "- .iloc <- Index by integer/positional\n",
    "- .loc  <- Index by labels [can be integer labels!]\n",
    "\n",
    "- .ix   <- Supports both label and integer/positional indexing. Tries to go by label first, and then positional indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .iloc grabs by Positional indexing\n",
    "df.iloc[0] #Grab the 0th index row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[0:3] #Grab the 0 to 3th index row (NON INCLUSIVE END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .iloc can grab subsets of the dataframe through slicing\n",
    "df.iloc[0:3, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .loc grabs by label\n",
    "df.loc['2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .loc can also grab slices (INCLUSIVE END)\n",
    "df.loc['2015-01-01':'2015-01-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .loc can grab subsets of the dataframe through slicing\n",
    "df.loc['2015-01-01':'2015-01-03',['mon','tues']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .ix allows for both label and positional indexing\n",
    "df.ix['2015-01-01']\n",
    "df.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .ix can also mix label and positional indexing\n",
    "df.ix[1:3,['sun','mon','thurs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about adding rows into the dataframe using `iloc`, `loc`, and `ix`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Iloc does not work. What would the index label have been for this anyway?\n",
    "df.iloc[5] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loc works as of Pandas .13\n",
    "df.loc[pd.Timestamp('2015-01-06')] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ix also works when using label.\n",
    "df.ix[pd.Timestamp('2015-01-07')] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, even if using ix, if we pass in a positional label, wont work\n",
    "df.ix[7] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following two blocks are important when using integer indexes. Make sure you understand, or your code can be prone to bugs!**\n",
    "\n",
    "* When you have a pure integer based index, `loc` will look for the integer label you specify. i.e. df.loc[3] will look for the row with index label == 3.\n",
    "* When you have a pure integer based index, `iloc` will use the positional indexes you specify. i.e. df.iloc[3] will return the 4th row.\n",
    "* When you have a pure integer based index, `ix` will look for the integer label you specify. i.e. df.ix[3] will look for the row with index label == 3\n",
    "* When you have a mixed index containing integers, `ix` will use positional indexing! i.e. df.ix[3] will return the 4th row.\n",
    "\n",
    "\n",
    "More information at:\n",
    "[Good explanation for loc vs iloc vs ix](http://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanation/31593712#31593712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.Series(1, index=[49,48,47,46,45,1,2,3,4,5])\n",
    "print df, '\\n'\n",
    "print 'Positional locate:'\n",
    "print df.iloc[:3], '\\n' #Positional locate.\n",
    "print 'Label locate:'\n",
    "print df.loc[:3], '\\n' #Label locate. Goes up to and includes label\n",
    "print 'Ix locate:'\n",
    "print df.ix[:3], '\\n'  #Tries first to do label loc.\n",
    "\n",
    "print df.iloc[:6], '\\n'\n",
    "#print df.ix[:6]   #Fails. There is no label loc\n",
    "\n",
    "#If labels, then use loc\n",
    "#If integers, then use iloc\n",
    "#Use ix when you have to mix integers and labels\n",
    "\n",
    "#When there are mixed types in the index, ix falls back to positional indexing\n",
    "df = pd.Series(1, index=['a','b','c',5,6,21])\n",
    "print df, '\\n'\n",
    "print df.ix[:5] #Falls back to positional indexing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random((3,2)),index=[100,200,300],columns=['A','B'])\n",
    "print df, '\\n'\n",
    "print df.iloc[0], '\\n'\n",
    "print df.loc[100], '\\n'\n",
    "print df.ix[0] #This wont work because the index is integer based, and ix looks for label==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create a dataframe where the indexes are every day from 1/1/2015 to 1/10/2015 and the columns are `a` and `b`. Generate the datapoints randomly from your favorite random function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2) Grab the rows of the dataframe where date is between '2015-01-06' and '2015-01-09' (inclusive) using `loc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3) Grab the third through fifth rows of the dataframe (exclusive) using `iloc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Insert a row of random numbers into the data frame having date 2015-01-11. **\n",
    "\n",
    "**Hint1: If you have trouble, remember the type of the index you are inserting\n",
    "Hint2: Remember that Pandas adds rows by matching up index/column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple indexing\n",
    "Pandas allows you to have more than one set of indices or columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(np.random.randn(30,5),\n",
    "                   index=pd.date_range('2015-1-1','2017-7-1',freq='m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['blah'] = ['b1','b2','b3']*10\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.reset_index() #Reset the index of df3, set it as a new column\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.set_index(['blah','index'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.index.names = ['blah','date']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.index #The Index type is a \"MultiIndex\" having a list of indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc['b1'] #Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[ [pd.Timestamp('2015-01-31')]  ] #doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[('b1','2015-01-31')] # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can address up until the left most unaddressed level\n",
    "df4 = pd.DataFrame(np.random.randn(8),index=['idx'+str(x) for x in range(8)])\n",
    "df4['foobar'] = ['foo','foo','bar','bar']*2\n",
    "df4['fahfoo'] = ['fah','bah']*4\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df4.reset_index().set_index(['fahfoo','foobar','index'])\n",
    "df4.index.names = ['fahfoo','foobar','idx3']\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.loc[ ('fah','foo') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Group By: Split-Apply-Combine\n",
    "Pandas provides for powerful aggregation within 'groups'. The process involves:\n",
    "* **Splitting** the data into groups based on criteria\n",
    "* **Applying** a function to each of the groups independently\n",
    "* **Combining** the groups back together into a dataframe\n",
    "\n",
    "The **Apply** step can be any function such as Aggregating values (mean,min,median,count,etc), Transforming values (similar to the winsorization example), or Filtration (removing data)\n",
    "\n",
    "The most similar paradigm would be SQL based statements such as:\n",
    "```\n",
    "SELECT column1, mean(column2), max(column3)\n",
    "FROM TheTable\n",
    "GROUP BY column1, column2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['foo','bar','foo','bar',\n",
    "                         'foo','bar','foo','foo'],\n",
    "                   'B': ['one','one','two','three',\n",
    "                         'two','two','one','three'],\n",
    "                   'C': np.random.randint(0,10,8),\n",
    "                   'D': np.random.randint(0,10,8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Groupby` objects are essentially mappings between 'groupings' and the set of indices the grouping is associated with. `Groupby` does NOT split. It just validates a correct mapping of labels to group names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('A') #groupby object. Group by the unique A's\n",
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\"\n",
    "    print group, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['A','B']) # Group by unique combn of A's and B's\n",
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\"\n",
    "    print group, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can also split on rows. You can specify your own rules\n",
    "grouped = df.groupby(lambda x: 'Even' if x%2==0 else 'Odd', axis=0)\n",
    "\n",
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\"\n",
    "    print group, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.groups #Get mapping of group to the LABELS in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can also split on columns. You can specify your own rules\n",
    "def tmp(letter):\n",
    "    if letter.lower() in 'aeiou':\n",
    "        return 'vowel'\n",
    "    else:\n",
    "        return 'consonant'\n",
    "\n",
    "grouped = df.groupby(tmp, axis=1)\n",
    "grouped.get_group('consonant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.groups #Get mapping of group to the LABELS in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Another example, doing grouping on the columns\n",
    "multiIdx = pd.MultiIndex.from_tuples(    \n",
    "    list(zip(*[ ['fah','bah']*4,['foo','foo','bar','bar']*2])),\n",
    "    names=['fahbah','foobar'])\n",
    "\n",
    "df4 = pd.DataFrame({'A': np.random.randint(0,10,8),\n",
    "                    'B': np.random.randint(0,10,8)},\n",
    "                   index=multiIdx)\n",
    "\n",
    "grouped = df4.groupby(level=0)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Various descriptive stats measured on each of the groups\n",
    "grouped.all() # All of the elements are true (or coercible to true)\n",
    "grouped.any()\n",
    "grouped.count()\n",
    "grouped.count()\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can specifiy an aggregation functions\n",
    "grouped.agg(np.mean) #Specify existing functions\n",
    "\n",
    "#Or even write your own\n",
    "grouped.agg( lambda x: np.sum(x)/np.float64(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can handle multiple aggregations on the columns through dicts\n",
    "grouped.agg({'A': ['mean','min','max'], 'B': ['count','nunique']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#you can also do in place transformations of the data\n",
    "def zScore(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "grouped = df4.groupby(level=1)\n",
    "#Group by 'fah' and 'bah', take all of the elements in them and zscore\n",
    "grouped.transform(zScore) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using transform, check that your transformation function actually returns the same number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Does not do what you think. \n",
    "#Notice that each element got of 'fah' got the same mean\n",
    "grouped.transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply is similar to transform, but resulting shape not necessarily same\n",
    "df4.groupby(level=0).apply(lambda x: (x.max(), x.min()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What?\n",
    "\n",
    "`apply` applies a function to each group. The sizes can be different.\n",
    "\n",
    "`agg` applies a function to each column for each group to reduce down to a single value.\n",
    "\n",
    "`transform` applies a function to each group, but the result must be the same size as that which is passed in. (ideal for: standardization, winsorization, demeaning, filling NAs with the mean etc)\n",
    "\n",
    "For more information: [Groupby](http://pandas.pydata.org/pandas-docs/stable/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Pandas also has the ability to dynamically download datasets using the read_csv function.\n",
    "\n",
    "Download the following dataset using the following command. Note that this may take a while--you'll know if Python is still running if there is an asterisk to the left of the command\n",
    "```\n",
    "import pandas as pd\n",
    "chi = pd.read_csv('https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv?accessType=DOWNLOAD')\n",
    "chi.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What is the shape of this data set? How many rows and columns are there?\n",
    "\n",
    "Hint: .info() or shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many distinct cities are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common Inspection Type? Hint: Use `groupby` and `idxmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
