{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors (kNN) and the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.wpclipart.com/plants/diagrams/plant_parts/petal_sepal_label.png\" \n",
    " style=\"height: 170px;\"/ align=left>\n",
    "<img src=\"http://articles.concreteinteractive.com/wp-content/uploads/2015/03/irises.png\"\n",
    " style=\"height: 170px;\"/ align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise involves Fisher's iris dataset. Although you could technically do your data mining without knowing what an iris is, it is definitely recommended that you'd make yourself a little familiar with the subject. \n",
    "(Recall that data science = math + coding + domain knowledge.) For now, though, looking at the above pictures is probably enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://www.stat.cmu.edu/~rnugent/PUBLIC/teaching/CMU729/HW/iris.txt',sep=' ')\n",
    "data.columns =  ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have three kinds of irises, and 50 samples of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We would like to classify the irises into one of these three species, based on the four given features.\n",
    "- First have a look at some basic statistics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = data.columns.tolist()[:-1]\n",
    "species = data.species.unique()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Average sizes per feature per species\n",
    "data.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Good, but lets get some more stats\n",
    "data.groupby('species').agg(['mean','min','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Set up color labeling\n",
    "colors = pd.Series(['y', 'r', 'b'], index=species)\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sepal: length vs width\n",
    "x_feature, y_feature = 'sepal_length', 'sepal_width'\n",
    "for spec in species:\n",
    "    data_spec = data[data.species == spec]\n",
    "    plt.scatter(data_spec[x_feature], data_spec[y_feature], c=colors[spec], label=spec,\n",
    "                linewidths=0, s=50, alpha=.8)\n",
    "    plt.xlabel('sepal_length'), plt.ylabel('sepal_width')\n",
    "f = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Petal: length vs width\n",
    "x_feature, y_feature = 'petal_length', 'petal_width'\n",
    "for spec in species:\n",
    "    data_spec = data[data.species == spec]\n",
    "    plt.scatter(data_spec[x_feature], data_spec[y_feature], c=colors[spec], label=spec,\n",
    "                linewidths=0, s=50, alpha=.8)\n",
    "    plt.xlabel('sepal_length'), plt.ylabel('sepal_width')\n",
    "f = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hmm...lets try all the things!\n",
    "import itertools\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx, val in enumerate(itertools.combinations(features,2)):\n",
    "    x_feature, y_feature = val\n",
    "    plt.subplot(3,2,idx+1)\n",
    "    for spec in species:\n",
    "        data_spec = data[data.species == spec]\n",
    "        plt.scatter(data_spec[x_feature], data_spec[y_feature], c=colors[spec], label=spec,\n",
    "                linewidths=0, s=50, alpha=.8)\n",
    "        plt.xlabel(x_feature)\n",
    "        plt.ylabel(y_feature)\n",
    "    f = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  # Import the KNN algorithm from sk-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)  # init kNN, with k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = data[features]  # put our features in a separate matrix, this is the 'input'\n",
    "y = data.species  # these are the labels we would like to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)  # fit the model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take our first sample and see if it predicts that one correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What are the features of the first few samples?\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What was the label of our first sample?\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What does our model predict it would be?\n",
    "model.predict(X.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#What does the model predict for all the samples?\n",
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the accuracy for the entire dataset? How many % of samples can we predict correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "97% Correct. Not bad...but is the above number correct? Let's try to calculate it ourselves.\n",
    "\n",
    "**1) First, predict y using `model.predict`, and save it to y_pred**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our quality measure, will be #Predictions correct / Total # Predictions.\n",
    "\n",
    "**2) Calculate this quality measure now. It may be beneficial to use np.sum. Check that the resulting number is the same**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- However, this number is because we tested on the training set. The above method could be seen as cheating, since we had given all answers to the model to start with. \n",
    "\n",
    "**3) To illustrate this, try the process of fitting, predicting, and scoring using $k=1$ and see what happens.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train vs Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wow, 100% accuracy! Why do you think that is?\n",
    "- Does this mean that our model performs better when we choose $k = 1$ than with the $k$ we chose earlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To avoid this problem, we split up the dataset in a **training set** for fitting the model, and a **test set** for testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)  # Use 80% of the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)  # Let's do the extreme case of k=1 first\n",
    "model.fit(X_train, y_train)\n",
    "print \"Accuracy on training set:\", model.score(X_train, y_train)\n",
    "print \"Accuracy on test set:    \", model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=20)  # Let's try with a lot more neighbors\n",
    "model.fit(X_train, y_train)\n",
    "print \"Accuracy on training set\", model.score(X_train, y_train)\n",
    "print \"Accuracy on test set:   \", model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Let's get a rough idea of how our training and test error changes as a function of $k$.\n",
    "\n",
    "**1) Create two arrays. Call them trainScore and testScore respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Split up the dataset into X_train, X_test, y_train, y_test as we did above using train_size = .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) For $k = 1, 2, 3, ..., 70$, fit a model using the particular value of k. Append the score on the training set to $trainScore$, and append the score on the test set to $testScore$ respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Plot both trainScore and testScore on a single plot. You can call plt.plot and pass in your arrays twice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above sections of code a few times, you might see that your plots will change a lot. Generally, as you increase 'k', the training score will decrease, while test score will increase. At a certain point, they will both start to decrease. This is due to a bias-variance tradeoff that we will explore later on. \n",
    "\n",
    "Attempting to choose the best $k$ using our current setup will lead to bias in our results. Why is that? Imagine that we keep the train and test set constant and we only vary k. If we try to choose the best k based on what gives us the highest test score, then we've only really picked the best k for THIS split of data. We will also explore solutions to reducing this issue through cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the oenophiles out there, let's try to classify some wines based on some qualities about the wine. First download the following dataset, and use the column_names attribute to set the column names.\n",
    "```\n",
    "column_names = ['wine','alcohol','malic_acid','ash','alcalinity','magnesium','total_phenols','flavanoids','nonflavanoid_phenols','proanthocyanins','color_intensity','hue','od280','proline']\n",
    "\n",
    "x = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',names=column_names)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many samples of each class are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out some descriptive stats (mean,min,max) of each column by each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Split out the wine dataset into an X train matrix, X test matrix, y train array, y test array. Use 80% of the dataset for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize knn on 5 neighbors, and generate the train and test scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a few other values of k. How does your model compare?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try removing a few features. How does your model compare?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Exercise: Implementing kNN yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this exercise is to write the entire kNN algorithm yourself in python. This is a great exercise for those students who'd like to master the math *and* coding behind the algorithm.\n",
    "- The code below has defined a kNN class with empty functions.\n",
    "- Review the code. There are three methods that you need to complete: `fit`, `predict` and `score`.\n",
    "- Compare this implementation with the sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class kNN(object):\n",
    "    \"\"\"\n",
    "    Class for simple k-Nearest Neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=5):\n",
    "        \"\"\"\n",
    "        Initialize model.\n",
    "        :param k: number of Neighbors (the 'k' in kNN)\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit model.\n",
    "        :param X: pandas dataframe or numpy ndarray with features\n",
    "        :param y: pandas series or numpy ndarray with classes\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict classes of samples.\n",
    "        :param X: pandas dataframe or numpy ndarray with features\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute accuracy of predictions on X.\n",
    "        :param X: pandas dataframe or numpy ndarray with features\n",
    "        :param y: pandas series or numpy ndarray with true classes\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "model = knn.kNN(k=15)\n",
    "model.fit(X, y)\n",
    "model.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
